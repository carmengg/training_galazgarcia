---
title: "cleaning_and_wrangling_data_KEY"
author: CGG
format: html
---

Setup:

- delete everything below the header

- create the following sections:

    - Load Libraries
    - Load Data
    - Data Cleaning & Wrangling

## Load Libraries
        
```{r}
#| warning: false

library(dplyr)
library(tidyr)
library(readr)
```


# Load Data

https://bit.ly/data-wrangle-lesson-data

::: callout-tip
## Setup

1. Go to [KNB Data Package Alaska commercial salmon catches by management region (1886- 1997)](https://knb.ecoinformatics.org/view/df35b.304.2)

2. Find the data file `byerlySalmonByRegion.csv`. Right click the "Download" button and select "Copy Link Address"

3. Paste the copied URL into the `read_csv()` function

The code chunk you use to read in the data should look something like this:

```{r}
#| message: false
catch_original <- read_csv("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1")
```

**Note for Windows users:** Keep in mind, if you want to replicate this workflow in your local computer you also need to use the `url()` function here with the argument `method = "libcurl"`. 

It would look like this:

```{r}
#| eval: false
catch_original <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1", method = "libcurl"))
```

:::

```{r}
#| message: false
catch_original <- read_csv("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1")
```


# Initial Data Exploration

```{r}
## Prints the column names of my data frame
colnames(catch_original)
```

```{r}
## First 6 lines of the data frame
head(catch_original)
```

```{r}
## Summary of each column of data
summary(catch_original)
```

```{r}
## Prints unique values in a column (in this case, the region)
unique(catch_original$Region)
```

```{r}
## Opens data frame in its own tab to see each row and column of the data
#View(catch_original)
```

## Pipe operator

Go back to slides

## Selecting columns
We want to remove the `All` and the `notesRegCode` columns.
```{r}
catch_data <- catch_original %>% 
    select("Region","Year","Chinook","Sockeye","Coho","Pink","Chum")
```

The `select()` function also allows you to say which columns you *don't* want, by passing unquoted column names preceded by minus (`-`) signs:

```{r}
#| eval: false

# do it in console
catch_original %>% select(-All,-notesRegCode)
```


## Quality Check

```{r}
dplyr::glimpse(catch_data)
```
Does anything look weird? A: Chinook <chr>

# Change column content `mutate()`

We can use the `mutate()` function to change a column, or to create a new column. 

First, let's try to convert the Chinook catch values to `numeric` type using the `as.numeric()` function, and overwrite the old Chinook column.

```{r}
catch_clean <- 
    catch_data %>% 
    mutate(Chinook = as.numeric(Chinook))

#catch_clean
```

We get a warning ``"NAs introduced by coercion"`` which is R telling us that it couldn't convert every value to an integer and, for those values it couldn't convert, it put an `NA` in its place. 

This is behavior we commonly experience when cleaning data sets and it's important to have the skills to deal with it when it comes up.

## Find row with `NA`

To investigate, let's isolate the issue. 

We can find out which values are `NA`s with a combination of `is.na()` and `which()`, and save that to a variable called `i`.

```{r}
# Run each of these by parts in the console
which(is.na(catch_clean$Chinook))
```


```{r}
# alternatively 
i <- catch_clean$Chinook %>% is.na() %>% which()
i
```

It looks like there is only one problem row, lets have a look at it in the original data.

```{r}
catch_data[i,]
```
## Change I char value to 1 numeric

GOAL: (assume there are many values of "I" in the Chinook dataframe) change the value of the `Chinook` column to 1 if the value is equal to `I`, 

1. start with the catch_data dataframe, the final result will be stored in catch_clean    
`catch_clean <- catch data`

2. %>% : catch_data is the input to mutate()    

```
catch_clean <- catch_data %>%
    mutate()
```

3. name of column to mutate = Chinook (this will overwrite the existing Chinook column)

```
catch_clean <- catch_data %>%
    mutate(Chinook = )
```

4. we want to update the values of Chinook based on an "if-else" condition

```
catch_clean <- catch_data %>%
    mutate(Chinook = 
               if_else())
```

5. specify the condition: this means find all values in the Chinook column that equal “I”

```
catch_clean <- catch_data %>%
    mutate(Chinook = 
               if_else(condition = Chinook == "I")
               )
```

6. specify how to change values based on condition: 

if a value in Chinook == “I”,   
then replace it by “1”,    
else, keep the same value   


```{r}
catch_clean <- catch_data %>%
    mutate(Chinook = 
               if_else(condition = Chinook == "I", 
                             true = "1", 
                             false = Chinook))

##check
catch_clean[i, ]
```


Now we can convert to numeric in the same mutate code:

```{r}
catch_clean <- catch_data %>%
    mutate(Chinook = if_else(condition = Chinook == "I", 
                             true = "1", 
                             false = Chinook),
           Chinook = as.numeric(Chinook))

##check
catch_clean[i, ]
```

## `pivot_longer()` and `pivot_wider`

data are in a wide format and we want the data in a long format instead. 

`pivot_longer()` from the `tidyr` package helps us do  this conversion. 

```{r}
catch_long <- catch_clean %>% 
    #pivot longer all columns except Region and Year
    pivot_longer(
        cols = -c(Region, Year),
        names_to = "species",
        values_to = "catch"
    )

head(catch_long)
```

- The first argument to `pivot_longer` is the columns over which we are pivoting. You can select these by listing either the names of the columns you do want to pivot, or in this case, the names of the columns you are not pivoting over. 

- The `names_to` argument: this is the name of the column that you are creating from the column **names** of the columns you are pivoting over. 

- The `values_to` argument: the name of the column that you are creating from the **values** in the columns you are pivoting over.

The opposite of `pivot_longer()` is the `pivot_wider()` function. It works in a similar declarative fashion:

```{r}
catch_wide <- catch_long %>%
    pivot_wider(names_from = species,
                values_from = catch)

head(catch_wide)
```

Same than we did above we can pull up the documentation of the function to remind ourselves what goes in which argument. Type `?pivot_wider` in the console.

## Renaming columns `rename()`

Notice the values in the `catch` column are very small (these are supposed to be annual catches). 

[the metadata](https://knb.ecoinformatics.org/#view/df35b.304.2) : `catch` column is in thousands of fish

GOAL: Rename the `catch` column to be called `catch_thousands` to be more accurate:

```{r}
catch_long <- catch_long %>%
    rename(catch_thousands = catch)

head(catch_long)
```

## Adding columns `mutate()`

GOAL: create a column `catch` with units of fish, instead of thousands of fish:

```{r}

catch_long <- catch_long %>%
    mutate(catch = catch_thousands * 1000)

head(catch_long)
```

let's delete the catch_thousands column since we don't need it anymore:

```{r}

catch_long <- catch_long %>%
    select(-catch_thousands)

head(catch_long)
```
## Summary statistics

GOAL: getting the average catch per region.

In our initial data exploration we saw there are 18 regions, we can easily see their names again:

```{r}
unique(catch_original$Region)
```

Strategy: Split-apply-combine

bit.ly
`bit.ly/3ppGUsQ`

![Split-Apply-Combine!](https://learning.nceas.ucsb.edu/2023-06-delta/images/regions-split-apply-combine.png)

1. **Split**: Split the data into logical groups (e.g., region, species, etc.)

2. **Apply**: Calculate some summary statistic on each group (e.g. mean catch *by* year, number of individuals *per* species)

3. **Combine**: Combine the statistic calculated on each group back together into a single table

Using `dplyr`:

```{r}
mean_region <- catch_long %>%
    group_by(Region) %>%
    summarize(mean_catch = mean(catch))

head(mean_region)
```

Let's see how the previous code implements the Split-Apply-Combine strategy:

1. `group_by(Region)`: this is telling R to **split** the dataframe and create a group for each different value in the column `Region`. R just keeps track of the groups, it doesn't return separate dataframes per region. 


2. `mean(catch)`: here `mean` is the function we want to **apply** to the column `catch` in each group.


3. `summarize(catch = mean(catch))` the function `summarize()` is used to **combine** the results of `mean(catch)` in each group into a single table. The argument `mean_catch = mean(catch)` indicates that the column having the results of `mean(catch)` will be named `mean_catch`. 

* GOAL: count the number of rows in each group. We have to use a special function from `dplyr`, `n()`.

```{r}
n_region <- catch_long %>%
    group_by(Region) %>%
    summarize(n = n())

head(n_region)
```

## `filter()`
`filter()` function to filter our `data.frame` to rows matching some condition

GOAL: go back to our original `data.frame` and do some `filter()`ing

```{r}
sse_catch <- catch_long %>%
    filter(Region == "SSE")

head(sse_catch)
```

::: callout-note
## Exercise

- Filter to just catches of over one million fish
- Filter to just Chinook from the SSE region
:::

```{r}
#| code-summary: "Answer"
#| eval: false

## Catches over a million fish
catch_million <- catch_long %>%
    filter(catch > 1000000)

## Chinook from SSE data
chinook_see <- catch_long %>%
    filter(Region == "SSE",
           species == "Chinook")

## OR
chinook_see <- catch_long %>%
    filter(Region == "SSE" & species == "Chinook")
```


## Sorting data using `arrange()`

The arrange() function is used to sort the rows of a data.frame.

GOAL: re-calculate mean catch by region, and then arrange() the output by mean catch:

```{R}
mean_region <- catch_long %>%
    group_by(Region) %>%
    summarize(mean_catch = mean(catch)) %>%
    arrange(mean_catch)

head(mean_region)
```


default sorting order of `arrange()` is to sort in ascending order. 

To reverse the sort order, wrap the column name inside the `desc()` function:

```{r}
mean_region <- catch_long %>%
    group_by(Region) %>%
    summarize(mean_catch = mean(catch)) %>%
    arrange(desc(mean_catch))

head(mean_region)
```

## `separate()` and `unite()`

The `separate()` function allow us to easily split a single column into numerous. Its complement, the `unite()` function, allows ys to combine multiple columns into a single one.

This can come in really handy when we need to split a column into two pieces by a consistent separator (like a dash).

Let's make a new data frame with fake data to illustrate this.

Here we have a set of site identification codes with information about the island where the site is (the first 3 letters) and a site number (the 3 numbers).

GOAL: create a column with just the island information.

```{r}
sites_df <- data.frame(site = c("HAW-101",
                            "HAW-103",
                            "OAH-320",
                            "OAH-219",
                            "MAI-039"))

sites_df %>%
    separate(site, c("island", "site_number"), "-")
```

::: callout-note
## Exercise

Split the `city` column in the data frame `cities_df` into `city` and `state_code` columns

```{r}
## create `cities_df`
cities_df <- data.frame(city = c("Juneau AK",
                                 "Sitka AK",
                                 "Anchorage AK"))
```
:::


```{r}
#| code-summary: "Answer"
colnames(cities_df)

cities_clean <- cities_df %>%
    separate(city, c("city", "state_code"), " ")
cities_clean
```


The `unite()` function does just the reverse of `separate()`.

If we have a data.frame that contains columns for year, month, and day, we might want to unite these into a single date column.

```{r}
dates_df <- data.frame(
    year = c("1930",
             "1930",
             "1930"),
    month = c("12",
              "12",
              "12"),
    day = c("14",
            "15",
            "16")
)

dates_df %>%
    unite(date, year, month, day, sep = "-")
```

## All code together


```{r}
#| catch: true
#| message: false
catch_original <- read_csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1", 
                               method = "libcurl"))

mean_region <- catch_original %>%
  select(-All, -notesRegCode) %>% 
  mutate(Chinook = ifelse(Chinook == "I", 1, Chinook)) %>% 
  mutate(Chinook = as.numeric(Chinook)) %>% 
  pivot_longer(-c(Region, Year), 
               names_to = "species", 
               values_to = "catch") %>%
  mutate(catch = catch*1000) %>% 
  group_by(Region) %>% 
  summarize(mean_catch = mean(catch)) %>% 
arrange(desc(mean_catch))

head(mean_region)
```


We have completed our lesson on Cleaning and Wrangling data. Before we break, let's practice our Github workflow.

## Stage > Commit > Pull > Push

::: callout-tip
## Steps

1. Save the `.Rmd` you have been working on for this lesson.
2. Knit the R Markdown file. This is a way to test everything in your code is working.
3. ```Stage > Commit > Pull > Push```
:::






